---------------------------------------
Begin Slurm Prolog: Dec-02-2025 14:28:24
Job ID:    3758953
User ID:   kalyono3
Account:   coc
Job name:  xv2_wind_debug
Partition: coc-gpu
QOS:       coc-ice
---------------------------------------
Starting debug job 3758953 on atl1-1-02-010-32-0
Tue Dec  2 14:28:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   44C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Running 1-epoch debug training...
main.py:9: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="conf", config_name="config")
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/job_logging:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:415: UserWarning: In config: Invalid overriding of hydra/hydra_logging:
Default list overrides requires 'override' keyword.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/defaults_list_override for more information.

  deprecation_warning(msg)
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
[rank: 0] Global seed set to 42
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
  rank_zero_warn(
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.
  rank_zero_warn(
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'train_metric' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['train_metric'])`.
  rank_zero_warn(
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'val_metric' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['val_metric'])`.
  rank_zero_warn(
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'test_metric' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['test_metric'])`.
  rank_zero_warn(
wandb: WARNING Path /home/hice1/kalyono3/xview2_strong_baseline/logs/wandb/ wasn't writable, using system temp directory.
wandb: WARNING Path /home/hice1/kalyono3/xview2_strong_baseline/logs/wandb/ wasn't writable, using system temp directory
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id ogvzgdyi.
wandb: Tracking run with wandb version 0.15.8
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Global seed set to 42
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
using weights from ResNet34_Weights.IMAGENET1K_V1
[[36m2025-12-02 14:30:39,773[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Added key: store_based_barrier_key:1 to store for rank: 0[0m
[[36m2025-12-02 14:30:39,774[0m][[34mtorch.distributed.distributed_c10d[0m][[32mINFO[0m] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.[0m
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /home/hice1/kalyono3/scratch/weights/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name         | Type              | Params
---------------------------------------------------
0 | model        | Res34_Unet_Double | 25.7 M
1 | loss_fn      | ComboLoss         | 0     
2 | train_metric | MultilabelF1Score | 0     
3 | val_metric   | MultilabelF1Score | 0     
4 | test_metric  | ModuleList        | 0     
---------------------------------------------------
25.7 M    Trainable params
0         Non-trainable params
25.7 M    Total params
102.914   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:19<00:19, 19.41s/it]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.87s/it]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/163 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/163 [00:00<?, ?it/s] Epoch 0:   1%|          | 1/163 [00:12<34:46, 12.88s/it]Epoch 0:   1%|          | 1/163 [00:12<34:46, 12.88s/it, v_num=gdyi, train_loss_step=1.240][[36m2025-12-02 14:31:41,206[0m][[34mtorch.nn.parallel.distributed[0m][[32mINFO[0m] - Reducer buckets have been rebuilt in this iteration.[0m
Epoch 0:   1%|          | 2/163 [00:13<17:43,  6.61s/it, v_num=gdyi, train_loss_step=1.240]Epoch 0:   1%|          | 2/163 [00:13<17:43,  6.61s/it, v_num=gdyi, train_loss_step=1.110]Epoch 0:   2%|â–         | 3/163 [00:13<11:59,  4.50s/it, v_num=gdyi, train_loss_step=1.110]Epoch 0:   2%|â–         | 3/163 [00:13<11:59,  4.50s/it, v_num=gdyi, train_loss_step=1.030]Epoch 0:   2%|â–         | 4/163 [00:13<09:07,  3.45s/it, v_num=gdyi, train_loss_step=1.030]Epoch 0:   2%|â–         | 4/163 [00:13<09:07,  3.45s/it, v_num=gdyi, train_loss_step=0.950]Epoch 0:   3%|â–Ž         | 5/163 [00:14<07:25,  2.82s/it, v_num=gdyi, train_loss_step=0.950]Epoch 0:   3%|â–Ž         | 5/163 [00:14<07:25,  2.82s/it, v_num=gdyi, train_loss_step=0.943]Epoch 0:   4%|â–Ž         | 6/163 [00:14<06:16,  2.40s/it, v_num=gdyi, train_loss_step=0.943]Epoch 0:   4%|â–Ž         | 6/163 [00:14<06:16,  2.40s/it, v_num=gdyi, train_loss_step=0.951]Epoch 0:   4%|â–         | 7/163 [00:14<05:27,  2.10s/it, v_num=gdyi, train_loss_step=0.951]Epoch 0:   4%|â–         | 7/163 [00:14<05:27,  2.10s/it, v_num=gdyi, train_loss_step=0.928]Epoch 0:   5%|â–         | 8/163 [00:15<04:51,  1.88s/it, v_num=gdyi, train_loss_step=0.928]Epoch 0:   5%|â–         | 8/163 [00:15<04:51,  1.88s/it, v_num=gdyi, train_loss_step=0.943]Epoch 0:   6%|â–Œ         | 9/163 [00:15<04:23,  1.71s/it, v_num=gdyi, train_loss_step=0.943]Epoch 0:   6%|â–Œ         | 9/163 [00:15<04:23,  1.71s/it, v_num=gdyi, train_loss_step=0.864]Epoch 0:   6%|â–Œ         | 10/163 [00:15<03:59,  1.57s/it, v_num=gdyi, train_loss_step=0.864]Epoch 0:   6%|â–Œ         | 10/163 [00:15<03:59,  1.57s/it, v_num=gdyi, train_loss_step=0.886]Epoch 0:   7%|â–‹         | 11/163 [00:16<03:41,  1.46s/it, v_num=gdyi, train_loss_step=0.886]Epoch 0:   7%|â–‹         | 11/163 [00:16<03:41,  1.46s/it, v_num=gdyi, train_loss_step=0.832]Epoch 0:   7%|â–‹         | 12/163 [00:16<03:26,  1.36s/it, v_num=gdyi, train_loss_step=0.832]Epoch 0:   7%|â–‹         | 12/163 [00:16<03:26,  1.36s/it, v_num=gdyi, train_loss_step=0.870]Epoch 0:   8%|â–Š         | 13/163 [00:16<03:12,  1.28s/it, v_num=gdyi, train_loss_step=0.870]Epoch 0:   8%|â–Š         | 13/163 [00:16<03:12,  1.28s/it, v_num=gdyi, train_loss_step=0.982]Epoch 0:   9%|â–Š         | 14/163 [00:17<03:09,  1.27s/it, v_num=gdyi, train_loss_step=0.982]Epoch 0:   9%|â–Š         | 14/163 [00:17<03:09,  1.27s/it, v_num=gdyi, train_loss_step=0.849]Epoch 0:   9%|â–‰         | 15/163 [00:18<02:58,  1.21s/it, v_num=gdyi, train_loss_step=0.849]Epoch 0:   9%|â–‰         | 15/163 [00:18<02:58,  1.21s/it, v_num=gdyi, train_loss_step=0.854]Epoch 0:  10%|â–‰         | 16/163 [00:18<02:49,  1.15s/it, v_num=gdyi, train_loss_step=0.854]Epoch 0:  10%|â–‰         | 16/163 [00:18<02:49,  1.15s/it, v_num=gdyi, train_loss_step=0.862]Epoch 0:  10%|â–ˆ         | 17/163 [00:18<02:40,  1.10s/it, v_num=gdyi, train_loss_step=0.862]Epoch 0:  10%|â–ˆ         | 17/163 [00:18<02:40,  1.10s/it, v_num=gdyi, train_loss_step=0.820]Epoch 0:  11%|â–ˆ         | 18/163 [00:18<02:32,  1.05s/it, v_num=gdyi, train_loss_step=0.820]Epoch 0:  11%|â–ˆ         | 18/163 [00:18<02:32,  1.05s/it, v_num=gdyi, train_loss_step=0.916]Epoch 0:  12%|â–ˆâ–        | 19/163 [00:19<02:27,  1.02s/it, v_num=gdyi, train_loss_step=0.916]Epoch 0:  12%|â–ˆâ–        | 19/163 [00:19<02:27,  1.02s/it, v_num=gdyi, train_loss_step=0.807]Epoch 0:  12%|â–ˆâ–        | 20/163 [00:22<02:38,  1.11s/it, v_num=gdyi, train_loss_step=0.807]Epoch 0:  12%|â–ˆâ–        | 20/163 [00:22<02:38,  1.11s/it, v_num=gdyi, train_loss_step=0.845]Epoch 0:  13%|â–ˆâ–Ž        | 21/163 [00:22<02:32,  1.07s/it, v_num=gdyi, train_loss_step=0.845]Epoch 0:  13%|â–ˆâ–Ž        | 21/163 [00:22<02:32,  1.07s/it, v_num=gdyi, train_loss_step=0.874]Epoch 0:  13%|â–ˆâ–Ž        | 22/163 [00:22<02:26,  1.04s/it, v_num=gdyi, train_loss_step=0.874]Epoch 0:  13%|â–ˆâ–Ž        | 22/163 [00:22<02:26,  1.04s/it, v_num=gdyi, train_loss_step=0.779]Epoch 0:  14%|â–ˆâ–        | 23/163 [00:23<02:23,  1.03s/it, v_num=gdyi, train_loss_step=0.779]Epoch 0:  14%|â–ˆâ–        | 23/163 [00:23<02:23,  1.03s/it, v_num=gdyi, train_loss_step=0.814]Epoch 0:  15%|â–ˆâ–        | 24/163 [00:23<02:18,  1.00it/s, v_num=gdyi, train_loss_step=0.814]Epoch 0:  15%|â–ˆâ–        | 24/163 [00:23<02:18,  1.00it/s, v_num=gdyi, train_loss_step=0.761]Epoch 0:  15%|â–ˆâ–Œ        | 25/163 [00:24<02:13,  1.03it/s, v_num=gdyi, train_loss_step=0.761]Epoch 0:  15%|â–ˆâ–Œ        | 25/163 [00:24<02:13,  1.03it/s, v_num=gdyi, train_loss_step=0.787]Epoch 0:  16%|â–ˆâ–Œ        | 26/163 [00:26<02:17,  1.00s/it, v_num=gdyi, train_loss_step=0.787]Epoch 0:  16%|â–ˆâ–Œ        | 26/163 [00:26<02:17,  1.00s/it, v_num=gdyi, train_loss_step=0.780]Epoch 0:  17%|â–ˆâ–‹        | 27/163 [00:26<02:12,  1.02it/s, v_num=gdyi, train_loss_step=0.780]Epoch 0:  17%|â–ˆâ–‹        | 27/163 [00:26<02:12,  1.02it/s, v_num=gdyi, train_loss_step=0.805]Epoch 0:  17%|â–ˆâ–‹        | 28/163 [00:27<02:13,  1.01it/s, v_num=gdyi, train_loss_step=0.805]Epoch 0:  17%|â–ˆâ–‹        | 28/163 [00:27<02:13,  1.01it/s, v_num=gdyi, train_loss_step=0.873]Epoch 0:  18%|â–ˆâ–Š        | 29/163 [00:28<02:09,  1.03it/s, v_num=gdyi, train_loss_step=0.873]Epoch 0:  18%|â–ˆâ–Š        | 29/163 [00:28<02:09,  1.03it/s, v_num=gdyi, train_loss_step=0.695]Epoch 0:  18%|â–ˆâ–Š        | 30/163 [00:28<02:06,  1.06it/s, v_num=gdyi, train_loss_step=0.695]Epoch 0:  18%|â–ˆâ–Š        | 30/163 [00:28<02:06,  1.06it/s, v_num=gdyi, train_loss_step=0.638]Epoch 0:  19%|â–ˆâ–‰        | 31/163 [00:28<02:02,  1.08it/s, v_num=gdyi, train_loss_step=0.638]Epoch 0:  19%|â–ˆâ–‰        | 31/163 [00:28<02:02,  1.08it/s, v_num=gdyi, train_loss_step=0.648]Epoch 0:  20%|â–ˆâ–‰        | 32/163 [00:30<02:05,  1.04it/s, v_num=gdyi, train_loss_step=0.648]Epoch 0:  20%|â–ˆâ–‰        | 32/163 [00:30<02:05,  1.04it/s, v_num=gdyi, train_loss_step=0.633]Epoch 0:  20%|â–ˆâ–ˆ        | 33/163 [00:31<02:02,  1.06it/s, v_num=gdyi, train_loss_step=0.633]Epoch 0:  20%|â–ˆâ–ˆ        | 33/163 [00:31<02:02,  1.06it/s, v_num=gdyi, train_loss_step=0.743]Epoch 0:  21%|â–ˆâ–ˆ        | 34/163 [00:31<02:01,  1.06it/s, v_num=gdyi, train_loss_step=0.743]Epoch 0:  21%|â–ˆâ–ˆ        | 34/163 [00:31<02:01,  1.06it/s, v_num=gdyi, train_loss_step=0.763]Epoch 0:  21%|â–ˆâ–ˆâ–       | 35/163 [00:32<01:58,  1.08it/s, v_num=gdyi, train_loss_step=0.763]Epoch 0:  21%|â–ˆâ–ˆâ–       | 35/163 [00:32<01:58,  1.08it/s, v_num=gdyi, train_loss_step=0.769]Epoch 0:  22%|â–ˆâ–ˆâ–       | 36/163 [00:32<01:55,  1.10it/s, v_num=gdyi, train_loss_step=0.769]Epoch 0:  22%|â–ˆâ–ˆâ–       | 36/163 [00:32<01:55,  1.10it/s, v_num=gdyi, train_loss_step=0.762]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 37/163 [00:33<01:52,  1.12it/s, v_num=gdyi, train_loss_step=0.762]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 37/163 [00:33<01:52,  1.12it/s, v_num=gdyi, train_loss_step=0.790]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 38/163 [00:34<01:54,  1.09it/s, v_num=gdyi, train_loss_step=0.790]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 38/163 [00:34<01:54,  1.09it/s, v_num=gdyi, train_loss_step=0.575]Epoch 0:  24%|â–ˆâ–ˆâ–       | 39/163 [00:35<01:51,  1.11it/s, v_num=gdyi, train_loss_step=0.575]Epoch 0:  24%|â–ˆâ–ˆâ–       | 39/163 [00:35<01:51,  1.11it/s, v_num=gdyi, train_loss_step=0.581]Epoch 0:  25%|â–ˆâ–ˆâ–       | 40/163 [00:36<01:52,  1.09it/s, v_num=gdyi, train_loss_step=0.581]Epoch 0:  25%|â–ˆâ–ˆâ–       | 40/163 [00:36<01:52,  1.09it/s, v_num=gdyi, train_loss_step=0.570]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 41/163 [00:36<01:49,  1.11it/s, v_num=gdyi, train_loss_step=0.570]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 41/163 [00:36<01:49,  1.11it/s, v_num=gdyi, train_loss_step=0.573]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 42/163 [00:37<01:48,  1.12it/s, v_num=gdyi, train_loss_step=0.573]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 42/163 [00:37<01:48,  1.12it/s, v_num=gdyi, train_loss_step=1.120]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 43/163 [00:37<01:45,  1.14it/s, v_num=gdyi, train_loss_step=1.120]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 43/163 [00:37<01:45,  1.14it/s, v_num=gdyi, train_loss_step=0.747]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 44/163 [00:39<01:47,  1.11it/s, v_num=gdyi, train_loss_step=0.747]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 44/163 [00:39<01:47,  1.11it/s, v_num=gdyi, train_loss_step=0.776]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 45/163 [00:39<01:44,  1.13it/s, v_num=gdyi, train_loss_step=0.776]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 45/163 [00:39<01:44,  1.13it/s, v_num=gdyi, train_loss_step=0.799]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 46/163 [00:40<01:44,  1.12it/s, v_num=gdyi, train_loss_step=0.799]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 46/163 [00:40<01:44,  1.12it/s, v_num=gdyi, train_loss_step=0.746]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 47/163 [00:41<01:41,  1.14it/s, v_num=gdyi, train_loss_step=0.746]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 47/163 [00:41<01:41,  1.14it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 48/163 [00:42<01:41,  1.13it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 48/163 [00:42<01:41,  1.13it/s, v_num=gdyi, train_loss_step=0.615]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 49/163 [00:42<01:39,  1.14it/s, v_num=gdyi, train_loss_step=0.615]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 49/163 [00:42<01:39,  1.14it/s, v_num=gdyi, train_loss_step=0.708]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 50/163 [00:44<01:40,  1.12it/s, v_num=gdyi, train_loss_step=0.708]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 50/163 [00:44<01:40,  1.12it/s, v_num=gdyi, train_loss_step=0.675]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 51/163 [00:44<01:38,  1.14it/s, v_num=gdyi, train_loss_step=0.675]Epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 51/163 [00:44<01:38,  1.14it/s, v_num=gdyi, train_loss_step=0.679]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 52/163 [00:45<01:36,  1.15it/s, v_num=gdyi, train_loss_step=0.679]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 52/163 [00:45<01:36,  1.15it/s, v_num=gdyi, train_loss_step=0.715]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/163 [00:45<01:34,  1.16it/s, v_num=gdyi, train_loss_step=0.715]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 53/163 [00:45<01:34,  1.16it/s, v_num=gdyi, train_loss_step=0.741]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 54/163 [00:46<01:34,  1.16it/s, v_num=gdyi, train_loss_step=0.741]Epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 54/163 [00:46<01:34,  1.16it/s, v_num=gdyi, train_loss_step=0.654]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 55/163 [00:46<01:32,  1.17it/s, v_num=gdyi, train_loss_step=0.654]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 55/163 [00:46<01:32,  1.17it/s, v_num=gdyi, train_loss_step=0.639]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 56/163 [00:49<01:34,  1.14it/s, v_num=gdyi, train_loss_step=0.639]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 56/163 [00:49<01:34,  1.14it/s, v_num=gdyi, train_loss_step=0.523]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 57/163 [00:49<01:32,  1.15it/s, v_num=gdyi, train_loss_step=0.523]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 57/163 [00:49<01:32,  1.15it/s, v_num=gdyi, train_loss_step=0.549]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 58/163 [00:49<01:30,  1.16it/s, v_num=gdyi, train_loss_step=0.549]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 58/163 [00:49<01:30,  1.16it/s, v_num=gdyi, train_loss_step=0.484]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 59/163 [00:50<01:28,  1.18it/s, v_num=gdyi, train_loss_step=0.484]Epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 59/163 [00:50<01:28,  1.18it/s, v_num=gdyi, train_loss_step=0.495]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 60/163 [00:51<01:27,  1.17it/s, v_num=gdyi, train_loss_step=0.495]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 60/163 [00:51<01:27,  1.17it/s, v_num=gdyi, train_loss_step=0.621]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 61/163 [00:51<01:26,  1.18it/s, v_num=gdyi, train_loss_step=0.621]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 61/163 [00:51<01:26,  1.18it/s, v_num=gdyi, train_loss_step=0.514]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 62/163 [00:53<01:27,  1.16it/s, v_num=gdyi, train_loss_step=0.514]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 62/163 [00:53<01:27,  1.16it/s, v_num=gdyi, train_loss_step=0.616]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 63/163 [00:53<01:25,  1.17it/s, v_num=gdyi, train_loss_step=0.616]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 63/163 [00:53<01:25,  1.17it/s, v_num=gdyi, train_loss_step=0.489]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 64/163 [00:54<01:25,  1.16it/s, v_num=gdyi, train_loss_step=0.489]Epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 64/163 [00:54<01:25,  1.16it/s, v_num=gdyi, train_loss_step=0.742]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 65/163 [00:55<01:23,  1.18it/s, v_num=gdyi, train_loss_step=0.742]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 65/163 [00:55<01:23,  1.18it/s, v_num=gdyi, train_loss_step=0.508]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 66/163 [00:56<01:22,  1.17it/s, v_num=gdyi, train_loss_step=0.508]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 66/163 [00:56<01:22,  1.17it/s, v_num=gdyi, train_loss_step=0.631]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 67/163 [00:56<01:21,  1.18it/s, v_num=gdyi, train_loss_step=0.631]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 67/163 [00:56<01:21,  1.18it/s, v_num=gdyi, train_loss_step=0.639]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 68/163 [00:58<01:21,  1.17it/s, v_num=gdyi, train_loss_step=0.639]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 68/163 [00:58<01:21,  1.17it/s, v_num=gdyi, train_loss_step=0.585]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69/163 [00:58<01:19,  1.18it/s, v_num=gdyi, train_loss_step=0.585]Epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69/163 [00:58<01:19,  1.18it/s, v_num=gdyi, train_loss_step=0.665]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 70/163 [00:59<01:19,  1.17it/s, v_num=gdyi, train_loss_step=0.665]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 70/163 [00:59<01:19,  1.17it/s, v_num=gdyi, train_loss_step=0.511]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 71/163 [01:00<01:17,  1.18it/s, v_num=gdyi, train_loss_step=0.511]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 71/163 [01:00<01:17,  1.18it/s, v_num=gdyi, train_loss_step=0.861]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 72/163 [01:00<01:16,  1.19it/s, v_num=gdyi, train_loss_step=0.861]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 72/163 [01:00<01:16,  1.19it/s, v_num=gdyi, train_loss_step=0.729]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 73/163 [01:00<01:15,  1.20it/s, v_num=gdyi, train_loss_step=0.729]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 73/163 [01:00<01:15,  1.20it/s, v_num=gdyi, train_loss_step=0.681]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 74/163 [01:02<01:15,  1.18it/s, v_num=gdyi, train_loss_step=0.681]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 74/163 [01:02<01:15,  1.18it/s, v_num=gdyi, train_loss_step=0.583]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 75/163 [01:03<01:14,  1.19it/s, v_num=gdyi, train_loss_step=0.583]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 75/163 [01:03<01:14,  1.19it/s, v_num=gdyi, train_loss_step=0.551]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 76/163 [01:04<01:13,  1.18it/s, v_num=gdyi, train_loss_step=0.551]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 76/163 [01:04<01:13,  1.18it/s, v_num=gdyi, train_loss_step=0.538]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 77/163 [01:04<01:12,  1.19it/s, v_num=gdyi, train_loss_step=0.538]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 77/163 [01:04<01:12,  1.19it/s, v_num=gdyi, train_loss_step=0.595]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 78/163 [01:04<01:10,  1.20it/s, v_num=gdyi, train_loss_step=0.595]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 78/163 [01:04<01:10,  1.20it/s, v_num=gdyi, train_loss_step=0.618]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 79/163 [01:05<01:09,  1.21it/s, v_num=gdyi, train_loss_step=0.618]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 79/163 [01:05<01:09,  1.21it/s, v_num=gdyi, train_loss_step=0.550]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 80/163 [01:06<01:09,  1.20it/s, v_num=gdyi, train_loss_step=0.550]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 80/163 [01:06<01:09,  1.20it/s, v_num=gdyi, train_loss_step=0.573]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 81/163 [01:07<01:07,  1.21it/s, v_num=gdyi, train_loss_step=0.573]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 81/163 [01:07<01:07,  1.21it/s, v_num=gdyi, train_loss_step=0.380]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 82/163 [01:08<01:07,  1.20it/s, v_num=gdyi, train_loss_step=0.380]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 82/163 [01:08<01:07,  1.20it/s, v_num=gdyi, train_loss_step=0.578]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 83/163 [01:08<01:06,  1.21it/s, v_num=gdyi, train_loss_step=0.578]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 83/163 [01:08<01:06,  1.21it/s, v_num=gdyi, train_loss_step=0.643]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 84/163 [01:09<01:05,  1.21it/s, v_num=gdyi, train_loss_step=0.643]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 84/163 [01:09<01:05,  1.21it/s, v_num=gdyi, train_loss_step=0.474]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 85/163 [01:09<01:03,  1.22it/s, v_num=gdyi, train_loss_step=0.474]Epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 85/163 [01:09<01:03,  1.22it/s, v_num=gdyi, train_loss_step=0.553]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 86/163 [01:10<01:02,  1.22it/s, v_num=gdyi, train_loss_step=0.553]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 86/163 [01:10<01:02,  1.22it/s, v_num=gdyi, train_loss_step=0.550]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 87/163 [01:10<01:01,  1.23it/s, v_num=gdyi, train_loss_step=0.550]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 87/163 [01:10<01:01,  1.23it/s, v_num=gdyi, train_loss_step=0.565]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 88/163 [01:12<01:02,  1.21it/s, v_num=gdyi, train_loss_step=0.565]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 88/163 [01:12<01:02,  1.21it/s, v_num=gdyi, train_loss_step=0.597]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 89/163 [01:13<01:00,  1.22it/s, v_num=gdyi, train_loss_step=0.597]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 89/163 [01:13<01:00,  1.22it/s, v_num=gdyi, train_loss_step=0.608]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 90/163 [01:13<00:59,  1.22it/s, v_num=gdyi, train_loss_step=0.608]Epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 90/163 [01:13<00:59,  1.22it/s, v_num=gdyi, train_loss_step=0.595]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 91/163 [01:13<00:58,  1.23it/s, v_num=gdyi, train_loss_step=0.595]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 91/163 [01:13<00:58,  1.23it/s, v_num=gdyi, train_loss_step=0.457]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 92/163 [01:14<00:57,  1.24it/s, v_num=gdyi, train_loss_step=0.457]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 92/163 [01:14<00:57,  1.24it/s, v_num=gdyi, train_loss_step=0.689]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 93/163 [01:14<00:56,  1.25it/s, v_num=gdyi, train_loss_step=0.689]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 93/163 [01:14<00:56,  1.25it/s, v_num=gdyi, train_loss_step=0.460]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 94/163 [01:16<00:56,  1.23it/s, v_num=gdyi, train_loss_step=0.460]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 94/163 [01:16<00:56,  1.23it/s, v_num=gdyi, train_loss_step=0.566]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 95/163 [01:16<00:55,  1.23it/s, v_num=gdyi, train_loss_step=0.566]Epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 95/163 [01:16<00:55,  1.23it/s, v_num=gdyi, train_loss_step=0.566]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 96/163 [01:17<00:53,  1.24it/s, v_num=gdyi, train_loss_step=0.566]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 96/163 [01:17<00:53,  1.24it/s, v_num=gdyi, train_loss_step=0.406]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 97/163 [01:17<00:52,  1.25it/s, v_num=gdyi, train_loss_step=0.406]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 97/163 [01:17<00:52,  1.25it/s, v_num=gdyi, train_loss_step=0.449]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 98/163 [01:17<00:51,  1.26it/s, v_num=gdyi, train_loss_step=0.449]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 98/163 [01:17<00:51,  1.26it/s, v_num=gdyi, train_loss_step=0.380]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 99/163 [01:18<00:50,  1.27it/s, v_num=gdyi, train_loss_step=0.380]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 99/163 [01:18<00:50,  1.27it/s, v_num=gdyi, train_loss_step=0.447]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100/163 [01:20<00:50,  1.25it/s, v_num=gdyi, train_loss_step=0.447]Epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100/163 [01:20<00:50,  1.25it/s, v_num=gdyi, train_loss_step=0.433]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/163 [01:20<00:49,  1.25it/s, v_num=gdyi, train_loss_step=0.433]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/163 [01:20<00:49,  1.25it/s, v_num=gdyi, train_loss_step=0.551]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 102/163 [01:21<00:48,  1.26it/s, v_num=gdyi, train_loss_step=0.551]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 102/163 [01:21<00:48,  1.26it/s, v_num=gdyi, train_loss_step=0.507]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 103/163 [01:21<00:47,  1.27it/s, v_num=gdyi, train_loss_step=0.507]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 103/163 [01:21<00:47,  1.27it/s, v_num=gdyi, train_loss_step=0.665]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 104/163 [01:22<00:46,  1.27it/s, v_num=gdyi, train_loss_step=0.665]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 104/163 [01:22<00:46,  1.27it/s, v_num=gdyi, train_loss_step=0.452]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 105/163 [01:22<00:45,  1.27it/s, v_num=gdyi, train_loss_step=0.452]Epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 105/163 [01:22<00:45,  1.27it/s, v_num=gdyi, train_loss_step=0.400]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 106/163 [01:24<00:45,  1.25it/s, v_num=gdyi, train_loss_step=0.400]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 106/163 [01:24<00:45,  1.25it/s, v_num=gdyi, train_loss_step=0.514]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 107/163 [01:24<00:44,  1.26it/s, v_num=gdyi, train_loss_step=0.514]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 107/163 [01:24<00:44,  1.26it/s, v_num=gdyi, train_loss_step=0.465]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 108/163 [01:25<00:43,  1.27it/s, v_num=gdyi, train_loss_step=0.465]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 108/163 [01:25<00:43,  1.26it/s, v_num=gdyi, train_loss_step=0.568]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 109/163 [01:25<00:42,  1.27it/s, v_num=gdyi, train_loss_step=0.568]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 109/163 [01:25<00:42,  1.27it/s, v_num=gdyi, train_loss_step=0.417]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 110/163 [01:26<00:41,  1.28it/s, v_num=gdyi, train_loss_step=0.417]Epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 110/163 [01:26<00:41,  1.28it/s, v_num=gdyi, train_loss_step=0.572]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 111/163 [01:26<00:40,  1.29it/s, v_num=gdyi, train_loss_step=0.572]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 111/163 [01:26<00:40,  1.29it/s, v_num=gdyi, train_loss_step=0.446]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 112/163 [01:28<00:40,  1.26it/s, v_num=gdyi, train_loss_step=0.446]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 112/163 [01:28<00:40,  1.26it/s, v_num=gdyi, train_loss_step=0.436]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 113/163 [01:29<00:39,  1.27it/s, v_num=gdyi, train_loss_step=0.436]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 113/163 [01:29<00:39,  1.27it/s, v_num=gdyi, train_loss_step=0.495]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 114/163 [01:29<00:38,  1.27it/s, v_num=gdyi, train_loss_step=0.495]Epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 114/163 [01:29<00:38,  1.27it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 115/163 [01:30<00:37,  1.28it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 115/163 [01:30<00:37,  1.28it/s, v_num=gdyi, train_loss_step=0.404]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 116/163 [01:30<00:36,  1.28it/s, v_num=gdyi, train_loss_step=0.404]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 116/163 [01:30<00:36,  1.28it/s, v_num=gdyi, train_loss_step=0.390]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 117/163 [01:30<00:35,  1.29it/s, v_num=gdyi, train_loss_step=0.390]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 117/163 [01:30<00:35,  1.29it/s, v_num=gdyi, train_loss_step=0.376]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/163 [01:33<00:35,  1.27it/s, v_num=gdyi, train_loss_step=0.376]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 118/163 [01:33<00:35,  1.27it/s, v_num=gdyi, train_loss_step=0.525]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 119/163 [01:33<00:34,  1.28it/s, v_num=gdyi, train_loss_step=0.525]Epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 119/163 [01:33<00:34,  1.28it/s, v_num=gdyi, train_loss_step=0.299]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 120/163 [01:33<00:33,  1.28it/s, v_num=gdyi, train_loss_step=0.299]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 120/163 [01:33<00:33,  1.28it/s, v_num=gdyi, train_loss_step=0.475]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 121/163 [01:34<00:32,  1.29it/s, v_num=gdyi, train_loss_step=0.475]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 121/163 [01:34<00:32,  1.29it/s, v_num=gdyi, train_loss_step=0.391]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 122/163 [01:34<00:31,  1.29it/s, v_num=gdyi, train_loss_step=0.391]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 122/163 [01:34<00:31,  1.29it/s, v_num=gdyi, train_loss_step=0.472]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 123/163 [01:34<00:30,  1.30it/s, v_num=gdyi, train_loss_step=0.472]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 123/163 [01:34<00:30,  1.30it/s, v_num=gdyi, train_loss_step=0.364]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 124/163 [01:36<00:30,  1.28it/s, v_num=gdyi, train_loss_step=0.364]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 124/163 [01:36<00:30,  1.28it/s, v_num=gdyi, train_loss_step=0.408]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 125/163 [01:37<00:29,  1.29it/s, v_num=gdyi, train_loss_step=0.408]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 125/163 [01:37<00:29,  1.29it/s, v_num=gdyi, train_loss_step=0.474]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 126/163 [01:38<00:28,  1.28it/s, v_num=gdyi, train_loss_step=0.474]Epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 126/163 [01:38<00:28,  1.28it/s, v_num=gdyi, train_loss_step=0.700]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 127/163 [01:38<00:27,  1.29it/s, v_num=gdyi, train_loss_step=0.700]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 127/163 [01:38<00:27,  1.29it/s, v_num=gdyi, train_loss_step=0.437]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 128/163 [01:38<00:27,  1.30it/s, v_num=gdyi, train_loss_step=0.437]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 128/163 [01:38<00:27,  1.30it/s, v_num=gdyi, train_loss_step=0.442]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 129/163 [01:39<00:26,  1.30it/s, v_num=gdyi, train_loss_step=0.442]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 129/163 [01:39<00:26,  1.30it/s, v_num=gdyi, train_loss_step=0.289]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 130/163 [01:41<00:25,  1.28it/s, v_num=gdyi, train_loss_step=0.289]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 130/163 [01:41<00:25,  1.28it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 131/163 [01:41<00:24,  1.29it/s, v_num=gdyi, train_loss_step=0.569]Epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 131/163 [01:41<00:24,  1.29it/s, v_num=gdyi, train_loss_step=0.351]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 132/163 [01:42<00:24,  1.29it/s, v_num=gdyi, train_loss_step=0.351]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 132/163 [01:42<00:24,  1.29it/s, v_num=gdyi, train_loss_step=0.382]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 133/163 [01:42<00:23,  1.29it/s, v_num=gdyi, train_loss_step=0.382]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 133/163 [01:42<00:23,  1.29it/s, v_num=gdyi, train_loss_step=0.334]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/163 [01:43<00:22,  1.30it/s, v_num=gdyi, train_loss_step=0.334]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 134/163 [01:43<00:22,  1.30it/s, v_num=gdyi, train_loss_step=0.443]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 135/163 [01:43<00:21,  1.30it/s, v_num=gdyi, train_loss_step=0.443]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 135/163 [01:43<00:21,  1.30it/s, v_num=gdyi, train_loss_step=0.453]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 136/163 [01:45<00:20,  1.29it/s, v_num=gdyi, train_loss_step=0.453]Epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 136/163 [01:45<00:20,  1.29it/s, v_num=gdyi, train_loss_step=0.467]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 137/163 [01:45<00:20,  1.30it/s, v_num=gdyi, train_loss_step=0.467]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 137/163 [01:45<00:20,  1.30it/s, v_num=gdyi, train_loss_step=0.467]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 138/163 [01:46<00:19,  1.30it/s, v_num=gdyi, train_loss_step=0.467]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 138/163 [01:46<00:19,  1.30it/s, v_num=gdyi, train_loss_step=0.372]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 139/163 [01:46<00:18,  1.30it/s, v_num=gdyi, train_loss_step=0.372]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 139/163 [01:46<00:18,  1.30it/s, v_num=gdyi, train_loss_step=0.461]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 140/163 [01:47<00:17,  1.31it/s, v_num=gdyi, train_loss_step=0.461]Epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 140/163 [01:47<00:17,  1.31it/s, v_num=gdyi, train_loss_step=0.414]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 141/163 [01:47<00:16,  1.31it/s, v_num=gdyi, train_loss_step=0.414]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 141/163 [01:47<00:16,  1.31it/s, v_num=gdyi, train_loss_step=0.440]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 142/163 [01:49<00:16,  1.29it/s, v_num=gdyi, train_loss_step=0.440]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 142/163 [01:49<00:16,  1.29it/s, v_num=gdyi, train_loss_step=0.297]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 143/163 [01:50<00:15,  1.30it/s, v_num=gdyi, train_loss_step=0.297]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 143/163 [01:50<00:15,  1.30it/s, v_num=gdyi, train_loss_step=0.432]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 144/163 [01:50<00:14,  1.30it/s, v_num=gdyi, train_loss_step=0.432]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 144/163 [01:50<00:14,  1.30it/s, v_num=gdyi, train_loss_step=0.355]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 145/163 [01:50<00:13,  1.31it/s, v_num=gdyi, train_loss_step=0.355]Epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 145/163 [01:50<00:13,  1.31it/s, v_num=gdyi, train_loss_step=0.443]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 146/163 [01:51<00:12,  1.31it/s, v_num=gdyi, train_loss_step=0.443]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 146/163 [01:51<00:12,  1.31it/s, v_num=gdyi, train_loss_step=0.578]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 147/163 [01:51<00:12,  1.32it/s, v_num=gdyi, train_loss_step=0.578]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 147/163 [01:51<00:12,  1.32it/s, v_num=gdyi, train_loss_step=0.450]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 148/163 [01:54<00:11,  1.29it/s, v_num=gdyi, train_loss_step=0.450]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 148/163 [01:54<00:11,  1.29it/s, v_num=gdyi, train_loss_step=0.331]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149/163 [01:54<00:10,  1.30it/s, v_num=gdyi, train_loss_step=0.331]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 149/163 [01:54<00:10,  1.30it/s, v_num=gdyi, train_loss_step=0.281]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/163 [01:55<00:10,  1.30it/s, v_num=gdyi, train_loss_step=0.281]Epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 150/163 [01:55<00:10,  1.30it/s, v_num=gdyi, train_loss_step=0.355]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 151/163 [01:55<00:09,  1.30it/s, v_num=gdyi, train_loss_step=0.355]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 151/163 [01:55<00:09,  1.30it/s, v_num=gdyi, train_loss_step=0.528]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 152/163 [01:56<00:08,  1.31it/s, v_num=gdyi, train_loss_step=0.528]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 152/163 [01:56<00:08,  1.31it/s, v_num=gdyi, train_loss_step=0.360]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 153/163 [01:56<00:07,  1.32it/s, v_num=gdyi, train_loss_step=0.360]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 153/163 [01:56<00:07,  1.32it/s, v_num=gdyi, train_loss_step=0.339]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 154/163 [01:58<00:06,  1.30it/s, v_num=gdyi, train_loss_step=0.339]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 154/163 [01:58<00:06,  1.30it/s, v_num=gdyi, train_loss_step=0.482]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 155/163 [01:58<00:06,  1.31it/s, v_num=gdyi, train_loss_step=0.482]Epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 155/163 [01:58<00:06,  1.31it/s, v_num=gdyi, train_loss_step=0.383]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 156/163 [01:59<00:05,  1.30it/s, v_num=gdyi, train_loss_step=0.383]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 156/163 [01:59<00:05,  1.30it/s, v_num=gdyi, train_loss_step=0.387]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 157/163 [02:00<00:04,  1.31it/s, v_num=gdyi, train_loss_step=0.387]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 157/163 [02:00<00:04,  1.31it/s, v_num=gdyi, train_loss_step=0.382]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 158/163 [02:00<00:03,  1.31it/s, v_num=gdyi, train_loss_step=0.382]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 158/163 [02:00<00:03,  1.31it/s, v_num=gdyi, train_loss_step=0.350]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 159/163 [02:00<00:03,  1.32it/s, v_num=gdyi, train_loss_step=0.350]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 159/163 [02:00<00:03,  1.32it/s, v_num=gdyi, train_loss_step=0.307]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 160/163 [02:01<00:02,  1.31it/s, v_num=gdyi, train_loss_step=0.307]Epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 160/163 [02:01<00:02,  1.31it/s, v_num=gdyi, train_loss_step=0.556]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 161/163 [02:02<00:01,  1.32it/s, v_num=gdyi, train_loss_step=0.556]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 161/163 [02:02<00:01,  1.32it/s, v_num=gdyi, train_loss_step=0.409]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 162/163 [02:03<00:00,  1.31it/s, v_num=gdyi, train_loss_step=0.409]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 162/163 [02:03<00:00,  1.31it/s, v_num=gdyi, train_loss_step=0.430]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s, v_num=gdyi, train_loss_step=0.430]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s, v_num=gdyi, train_loss_step=0.364]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   5%|â–         | 1/22 [00:00<00:04,  4.27it/s][A
Validation DataLoader 0:   9%|â–‰         | 2/22 [00:00<00:06,  3.33it/s][A
Validation DataLoader 0:  14%|â–ˆâ–Ž        | 3/22 [00:00<00:06,  3.17it/s][A
Validation DataLoader 0:  18%|â–ˆâ–Š        | 4/22 [00:01<00:05,  3.08it/s][A
Validation DataLoader 0:  23%|â–ˆâ–ˆâ–Ž       | 5/22 [00:01<00:05,  3.06it/s][A
Validation DataLoader 0:  27%|â–ˆâ–ˆâ–‹       | 6/22 [00:01<00:05,  3.05it/s][A
Validation DataLoader 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 7/22 [00:02<00:05,  2.61it/s][A
Validation DataLoader 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 8/22 [00:03<00:05,  2.44it/s][A
Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9/22 [00:03<00:05,  2.49it/s][A
Validation DataLoader 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10/22 [00:03<00:04,  2.53it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 11/22 [00:04<00:04,  2.57it/s][A
Validation DataLoader 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12/22 [00:04<00:03,  2.60it/s][A
Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 13/22 [00:04<00:03,  2.63it/s][A
Validation DataLoader 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 14/22 [00:05<00:03,  2.65it/s][A
Validation DataLoader 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 15/22 [00:06<00:02,  2.37it/s][A
Validation DataLoader 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 16/22 [00:06<00:02,  2.41it/s][A
Validation DataLoader 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 17/22 [00:06<00:02,  2.44it/s][A
Validation DataLoader 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 18/22 [00:07<00:01,  2.46it/s][A
Validation DataLoader 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 19/22 [00:07<00:01,  2.49it/s][A
Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 20/22 [00:07<00:00,  2.51it/s][A
Validation DataLoader 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 21/22 [00:08<00:00,  2.48it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:08<00:00,  2.53it/s][AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:14<00:00,  1.21it/s, v_num=gdyi, train_loss_step=0.364, val_loss=0.565, val_MultilabelF1Score=0.606]
`Trainer.fit` stopped: `max_epochs=1` reached.
[rank: 0] Global seed set to 42
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
                                                                        [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:14<00:00,  1.21it/s, v_num=gdyi, train_loss_step=0.364, val_loss=0.565, val_MultilabelF1Score=0.606, train_loss_epoch=0.593, train_MultilabelF1Score_epoch=0.476]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:15<00:00,  1.20it/s, v_num=gdyi, train_loss_step=0.364, val_loss=0.565, val_MultilabelF1Score=0.606, train_loss_epoch=0.593, train_MultilabelF1Score_epoch=0.476]
Error executing job with overrides: ['data=supervised_data', 'trainer.devices=1', 'trainer.max_epochs=1', 'group=wind_supervised_debug']
Traceback (most recent call last):
  File "main.py", line 43, in <module>
    main()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "main.py", line 35, in main
    trainer.test(network, data_module)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 735, in test
    return call._call_and_handle_interrupt(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 778, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 1009, in _run_stage
    return self._evaluation_loop.run()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 98, in run
    self.setup_data()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 150, in setup_data
    dataloaders = _request_dataloader(source)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 330, in _request_dataloader
    return data_source.dataloader()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 300, in dataloader
    return call._call_lightning_datamodule_hook(self.instance.trainer, self.name)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 164, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/home/hice1/kalyono3/xview2_strong_baseline/datasets/supervised_dataset.py", line 313, in test_dataloader
    self.test_dataset,
AttributeError: 'DirSplitSLDataModule' object has no attribute 'test_dataset'
wandb: Waiting for W&B process to finish... (failed 1).
wandb: 
wandb: Run history:
wandb:                         epoch â–â–â–â–â–
wandb: train_MultilabelF1Score_epoch â–
wandb:              train_loss_epoch â–
wandb:               train_loss_step â–ˆâ–ƒâ–
wandb:           trainer/global_step â–â–„â–‡â–ˆâ–ˆ
wandb:         val_MultilabelF1Score â–
wandb:                      val_loss â–
wandb: 
wandb: Run summary:
wandb:                         epoch 0
wandb: train_MultilabelF1Score_epoch 0.47557
wandb:              train_loss_epoch 0.59323
wandb:               train_loss_step 0.35502
wandb:           trainer/global_step 162
wandb:         val_MultilabelF1Score 0.60586
wandb:                      val_loss 0.56519
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /tmp/wandb/offline-run-20251202_143027-ogvzgdyi
wandb: Find logs at: /tmp/wandb/offline-run-20251202_143027-ogvzgdyi/logs
Traceback (most recent call last):
  File "main.py", line 43, in <module>
    main()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "main.py", line 35, in main
    trainer.test(network, data_module)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 735, in test
    return call._call_and_handle_interrupt(
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 778, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 1009, in _run_stage
    return self._evaluation_loop.run()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 98, in run
    self.setup_data()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 150, in setup_data
    dataloaders = _request_dataloader(source)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 330, in _request_dataloader
    return data_source.dataloader()
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 300, in dataloader
    return call._call_lightning_datamodule_hook(self.instance.trainer, self.name)
  File "/home/hice1/kalyono3/scratch/conda_venvs/xview2_strong_baseline/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 164, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/home/hice1/kalyono3/xview2_strong_baseline/datasets/supervised_dataset.py", line 313, in test_dataloader
    self.test_dataset,
AttributeError: 'DirSplitSLDataModule' object has no attribute 'test_dataset'
srun: error: atl1-1-02-010-32-0: task 0: Exited with exit code 1
---------------------------------------
Begin Slurm Epilog: Dec-02-2025 14:33:52
Job ID:        3758953
User ID:       kalyono3
Account:       coc
Job name:      xv2_wind_debug
Resources:     cpu=4,gres/gpu:v100=1,mem=16G,node=1
Rsrc Used:     cput=00:21:52,vmem=0,walltime=00:05:28,mem=48216K,energy_used=0
Partition:     coc-gpu
QOS:           coc-ice
Nodes:         atl1-1-02-010-32-0
---------------------------------------
